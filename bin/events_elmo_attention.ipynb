{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "\n",
    "from torch.nn import Parameter\n",
    "from torch.nn import MSELoss, L1Loss, SmoothL1Loss, CrossEntropyLoss\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from collections import Iterable, defaultdict\n",
    "\n",
    "from factslab.utility import load_glove_embedding\n",
    "from factslab.datastructures import ConstituencyTree, DependencyTree\n",
    "from factslab.pytorch.temporal_events_attention import Attention_mlp\n",
    "import torch\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Toy data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = [[\"The\", \"boy\", \"ran\", \"into\", \"the\", \"garden\", \"and\", \"started\", \"playing\", \".\"],\n",
    "     [\"Susan\", \"dies\", \".\", \"So\", \"does\", \"Jack\"],\n",
    "     [\"He\", \"belived\", \"in\", \"humanity\", \"but\", \"didn't\", \"believe\", \"in\", \"God\", \".\"],\n",
    "     [\"The\", \"man\", \"stole\", \"his\", \"umbrella\", \"and\", \"started\", \"running\", \".\"]]\n",
    "     \n",
    "spans = [ \n",
    "          [[1,2], [5,6,7]],\n",
    "          [[1,2,3], [4]],\n",
    "          [[1], [6]],\n",
    "          [[1,2,3], [5,6,7]]\n",
    "        ]\n",
    "         \n",
    "roots = [[2, 7],\n",
    "         [1, 4],\n",
    "        [1, 6],\n",
    "        [2, 6]]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "model1 = Attention_mlp(embedding_size=1024,\n",
    "                        pred_attention_type=None,\n",
    "                       relation_type=\"concat\", \n",
    "                       regression_hidden_sizes=[24,16], output_size=1,\n",
    "                         device=torch.device(type=\"cpu\"), batch_size=2)\n",
    "\n",
    "model2 = Attention_mlp(embedding_size=1024,\n",
    "                        pred_attention_type=\"const-span-attention\",\n",
    "                       relation_type=\"concat\", \n",
    "                       regression_hidden_sizes=[24,16], output_size=1,\n",
    "                         device=torch.device(type=\"cpu\"), batch_size=2)\n",
    "\n",
    "model3 = Attention_mlp(embedding_size=1024,\n",
    "                        pred_attention_type=\"param-span-attention\",\n",
    "                       relation_type=\"concat\", \n",
    "                       regression_hidden_sizes=[24,16], output_size=1,\n",
    "                         device=torch.device(type=\"cpu\"), batch_size=2)\n",
    "\n",
    "model4 = Attention_mlp(embedding_size=1024,\n",
    "                        pred_attention_type=None,\n",
    "                       relation_type=\"param-sent-attention\", \n",
    "                       regression_hidden_sizes=[24,16], output_size=1,\n",
    "                         device=torch.device(type=\"cpu\"), batch_size=2)\n",
    "\n",
    "model5 = Attention_mlp(embedding_size=1024,\n",
    "                        pred_attention_type=\"const-span-attention\",\n",
    "                       relation_type=\"param-sent-attention\", \n",
    "                       regression_hidden_sizes=[24,16], output_size=1,\n",
    "                         device=torch.device(type=\"cpu\"), batch_size=2)\n",
    "\n",
    "model6 = Attention_mlp(embedding_size=1024,\n",
    "                        pred_attention_type=\"param-span-attention\",\n",
    "                       relation_type=\"param-sent-attention\", \n",
    "                       regression_hidden_sizes=[24,16], output_size=1,\n",
    "                         device=torch.device(type=\"cpu\"), batch_size=2)\n",
    "\n",
    "models = [model1, model2, model3, model4, model5, model6]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Toy Outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([-0.1136, -0.2035], grad_fn=<SqueezeBackward0>)\n",
      "tensor([-0.1834, -0.0989], grad_fn=<SqueezeBackward0>)\n",
      "tensor([0.1353, 0.1841], grad_fn=<SqueezeBackward0>)\n",
      "tensor([0.0918, 0.0200], grad_fn=<SqueezeBackward0>)\n",
      "tensor([0.2911, 0.2882], grad_fn=<SqueezeBackward0>)\n",
      "tensor([-0.1958, -0.2061], grad_fn=<SqueezeBackward0>)\n"
     ]
    }
   ],
   "source": [
    "for model in models:\n",
    "    print(model(X[:2], spans[:2], roots[:2]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "########## .   Model 1 Parameters   ##############\n",
      "\n",
      "linear_maps.0.weight torch.Size([24, 2048])\n",
      "linear_maps.0.bias torch.Size([24])\n",
      "linear_maps.1.weight torch.Size([16, 24])\n",
      "linear_maps.1.bias torch.Size([16])\n",
      "linear_maps.2.weight torch.Size([1, 16])\n",
      "linear_maps.2.bias torch.Size([1])\n",
      "##############################################\n",
      "\n",
      "########## .   Model 2 Parameters   ##############\n",
      "\n",
      "linear_maps.0.weight torch.Size([24, 2048])\n",
      "linear_maps.0.bias torch.Size([24])\n",
      "linear_maps.1.weight torch.Size([16, 24])\n",
      "linear_maps.1.bias torch.Size([16])\n",
      "linear_maps.2.weight torch.Size([1, 16])\n",
      "linear_maps.2.bias torch.Size([1])\n",
      "att_map.weight torch.Size([1, 1024])\n",
      "##############################################\n",
      "\n",
      "########## .   Model 3 Parameters   ##############\n",
      "\n",
      "linear_maps.0.weight torch.Size([24, 2048])\n",
      "linear_maps.0.bias torch.Size([24])\n",
      "linear_maps.1.weight torch.Size([16, 24])\n",
      "linear_maps.1.bias torch.Size([16])\n",
      "linear_maps.2.weight torch.Size([1, 16])\n",
      "linear_maps.2.bias torch.Size([1])\n",
      "att_map.weight torch.Size([1024, 1024])\n",
      "att_map.bias torch.Size([1024])\n",
      "##############################################\n",
      "\n",
      "########## .   Model 4 Parameters   ##############\n",
      "\n",
      "linear_maps.0.weight torch.Size([24, 1024])\n",
      "linear_maps.0.bias torch.Size([24])\n",
      "linear_maps.1.weight torch.Size([16, 24])\n",
      "linear_maps.1.bias torch.Size([16])\n",
      "linear_maps.2.weight torch.Size([1, 16])\n",
      "linear_maps.2.bias torch.Size([1])\n",
      "sent_att_map.weight torch.Size([1024, 2048])\n",
      "sent_att_map.bias torch.Size([1024])\n",
      "##############################################\n",
      "\n",
      "########## .   Model 5 Parameters   ##############\n",
      "\n",
      "linear_maps.0.weight torch.Size([24, 1024])\n",
      "linear_maps.0.bias torch.Size([24])\n",
      "linear_maps.1.weight torch.Size([16, 24])\n",
      "linear_maps.1.bias torch.Size([16])\n",
      "linear_maps.2.weight torch.Size([1, 16])\n",
      "linear_maps.2.bias torch.Size([1])\n",
      "att_map.weight torch.Size([1, 1024])\n",
      "sent_att_map.weight torch.Size([1024, 2048])\n",
      "sent_att_map.bias torch.Size([1024])\n",
      "##############################################\n",
      "\n",
      "########## .   Model 6 Parameters   ##############\n",
      "\n",
      "linear_maps.0.weight torch.Size([24, 1024])\n",
      "linear_maps.0.bias torch.Size([24])\n",
      "linear_maps.1.weight torch.Size([16, 24])\n",
      "linear_maps.1.bias torch.Size([16])\n",
      "linear_maps.2.weight torch.Size([1, 16])\n",
      "linear_maps.2.bias torch.Size([1])\n",
      "att_map.weight torch.Size([1024, 1024])\n",
      "att_map.bias torch.Size([1024])\n",
      "sent_att_map.weight torch.Size([1024, 2048])\n",
      "sent_att_map.bias torch.Size([1024])\n",
      "##############################################\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for i,model in enumerate(models):\n",
    "    print(\"########## .   Model {} Parameters   ##############\\n\".format(i+1))\n",
    "    for name, param in model.named_parameters():\n",
    "        if param.requires_grad:\n",
    "            print(name, param.shape)\n",
    "    print(\"##############################################\\n\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (allennlp)",
   "language": "python",
   "name": "allennlp"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
