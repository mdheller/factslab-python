{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.cuda.is_available()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch._C.Generator at 0x2b666d9ce510>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import sys\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "\n",
    "from torch.nn import LSTM, GRU\n",
    "from torch.nn import Parameter\n",
    "from torch.nn import MSELoss, L1Loss, SmoothL1Loss, CrossEntropyLoss\n",
    "from torch.nn.utils.rnn import pad_packed_sequence\n",
    "from torch.nn.utils.rnn import pack_padded_sequence\n",
    "from scipy.special import huber\n",
    "from scipy.stats import spearmanr\n",
    "#from torch.autograd import Variable\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import math\n",
    "import json\n",
    "import re\n",
    "from nltk.tokenize import word_tokenize\n",
    "\n",
    "from collections import Iterable, defaultdict\n",
    "from tqdm import tqdm\n",
    "from tqdm import tqdm_notebook as tqdm_n\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "sys.path.insert(0, '/home/svashis3/factslab-python/factslab/')\n",
    "from utility import load_glove_embedding\n",
    "from datastructures import ConstituencyTree, DependencyTree\n",
    "\n",
    "torch.manual_seed(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "ud_trees = '../../UD_data_trees/structures.tsv'\n",
    "data_path = 'data_for_modelling_p1.pkl'\n",
    "embed_path = '../../'\n",
    "best_model_file = \"best_model_elmo_lstm_2.pth\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Initiate ELMO class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from allennlp.modules.elmo import Elmo, batch_to_ids\n",
    "\n",
    "options_file = \"https://s3-us-west-2.amazonaws.com/allennlp/models/elmo/2x4096_512_2048cnn_2xhighway/elmo_2x4096_512_2048cnn_2xhighway_options.json\"\n",
    "weight_file = \"https://s3-us-west-2.amazonaws.com/allennlp/models/elmo/2x4096_512_2048cnn_2xhighway/elmo_2x4096_512_2048cnn_2xhighway_weights.hdf5\"\n",
    "\n",
    "elmo = Elmo(options_file, weight_file, 1, dropout=0, requires_grad=False)  #using 1 layer of representation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load sentence mappings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['From', 'the', 'AP', 'comes', 'this', 'story', ':']\n"
     ]
    }
   ],
   "source": [
    "struct_dict = {}\n",
    "\n",
    "with open(ud_trees, 'r') as f:\n",
    "    structs_sents = [line.strip().split('\\t') for line in f]\n",
    "\n",
    "for sent_id, tree_list, sent in structs_sents:\n",
    "    struct_dict[sent_id] = DependencyTree.fromstring(tree_list)\n",
    "    struct_dict[sent_id].sentence = sent.split(\" \")\n",
    "    \n",
    "print(struct_dict['en-ud-dev.conllu sent_1'].sentence)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load the data :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_sentence(sentence_id):\n",
    "    '''\n",
    "    Extract the sentence given sent_var\n",
    "    '''\n",
    "    temp = sentence_id.split(\" \")\n",
    "    key = temp[0] + \" sent_\" + temp[1]\n",
    "    \n",
    "    return struct_dict[key].sentence\n",
    "\n",
    "data_all = pd.read_pickle(data_path)\n",
    "#Extract sentence\n",
    "data_all[\"sentence\"] = data_all.sentence_id.map(lambda x: extract_sentence(x))\n",
    "#data_all.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### View X and Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train shape: (23538, 2)\n",
      "Dev shape: (2884, 2)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sentence</th>\n",
       "      <th>pred_root_pos</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[Maybe, because, they, hint, at, a, larger, co...</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[I, read, of, a, case, not, long, ago, when, s...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[I, read, of, a, case, not, long, ago, when, s...</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[I, read, of, a, case, not, long, ago, when, s...</td>\n",
       "      <td>24</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[Of, course, law, enforcement, has, dragged, i...</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            sentence  pred_root_pos\n",
       "0  [Maybe, because, they, hint, at, a, larger, co...              3\n",
       "1  [I, read, of, a, case, not, long, ago, when, s...              1\n",
       "2  [I, read, of, a, case, not, long, ago, when, s...             12\n",
       "3  [I, read, of, a, case, not, long, ago, when, s...             24\n",
       "4  [Of, course, law, enforcement, has, dragged, i...              5"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train = data_all[data_all.split==\"train\"][['sentence', 'pred_root_pos']]\n",
    "X_dev = data_all[data_all.split==\"dev\"][['sentence', 'pred_root_pos']]\n",
    "\n",
    "print(\"Train shape: {}\".format(X_train.shape))\n",
    "print(\"Dev shape: {}\".format(X_dev.shape))\n",
    "\n",
    "X_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(23538,)\n",
      "(2884,)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0    8\n",
       "1    8\n",
       "2    6\n",
       "3    0\n",
       "4    6\n",
       "Name: duration, dtype: int64"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y_train = data_all[data_all.split==\"train\"]['duration']\n",
    "Y_dev = data_all[data_all.split==\"dev\"]['duration']\n",
    "\n",
    "print(Y_train.shape)\n",
    "print(Y_dev.shape)\n",
    "\n",
    "Y_train.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "class EventTypeRNN(torch.nn.Module):\n",
    "    def __init__(self, embeddings=None, embedding_size=1024, vocab=None,\n",
    "                 rnn_class=LSTM, rnn_hidden_size=300, rnn_dropout=0,\n",
    "                 num_rnn_layers=1, bidirectional=False, attention=False,\n",
    "                 regression_hidden_sizes=[], output_size=1,\n",
    "                 device=torch.device(type=\"cpu\"), batch_size=16):\n",
    "        super().__init__()\n",
    "\n",
    "        self.device = device\n",
    "        self.batch_size = batch_size\n",
    "        self.bidirectional = bidirectional\n",
    "        self.num_rnn_layers = num_rnn_layers\n",
    "        self.rnn_hidden_size = rnn_hidden_size\n",
    "        self.rnn_dropout = rnn_dropout\n",
    "        self.attention = attention\n",
    "        self.embedding_size = embedding_size\n",
    "        \n",
    "        # initialize model\n",
    "        self._initialize_rnn(rnn_class, rnn_hidden_size,\n",
    "                             num_rnn_layers, bidirectional)\n",
    "        self._initialize_regression(attention,\n",
    "                                    regression_hidden_sizes,\n",
    "                                    output_size) \n",
    "        \n",
    "        \n",
    "        \n",
    "    def _initialize_rnn(self, rnn_class, rnn_hidden_size,\n",
    "                        num_rnn_layers, bidirectional):\n",
    "        \n",
    "        self.rnn = rnn_class(input_size= self.embedding_size,\n",
    "                            hidden_size = self.rnn_hidden_size,\n",
    "                            num_layers= self.num_rnn_layers,\n",
    "                            bidirectional = self.bidirectional,\n",
    "                            batch_first = True,\n",
    "                            dropout = self.rnn_dropout)\n",
    "        \n",
    "        if self.bidirectional:\n",
    "            self.rnn_output_size = self.rnn_hidden_size*2\n",
    "        else:\n",
    "            self.rnn_output_size = self.rnn_hidden_size\n",
    "            \n",
    "        if self.batch_size > 1:\n",
    "            self.has_batch_dim = True\n",
    "        else:\n",
    "            self.has_batch_dim = False\n",
    "            \n",
    "    def _initialize_regression(self, attention, hidden_sizes, output_size):\n",
    "        self.linear_maps = nn.ModuleList()\n",
    "        \n",
    "        last_size = self.rnn_output_size\n",
    "\n",
    "        for h in hidden_sizes:\n",
    "            linmap = torch.nn.Linear(last_size, h)\n",
    "            linmap = linmap.to(self.device)\n",
    "            self.linear_maps.append(linmap)\n",
    "            last_size = h\n",
    "\n",
    "        linmap = torch.nn.Linear(last_size, output_size)\n",
    "        linmap = linmap.to(self.device)\n",
    "        self.linear_maps.append(linmap)\n",
    "    \n",
    "    \n",
    "    def forward(self, structures, idxs=None):\n",
    "        \n",
    "        #Create elmo dict\n",
    "        sentences = structures\n",
    "        character_ids = batch_to_ids(sentences)\n",
    "        embeddings_dict = elmo(character_ids)\n",
    "        \n",
    "        #inputs\n",
    "        inputs = embeddings_dict['elmo_representations'][0].to(self.device)\n",
    "        inputs = inputs.detach()  #if it doesn't require back-prop\n",
    "       \n",
    "        if not idxs:\n",
    "            lengths = torch.sum(embeddings_dict['mask'], dim=1).numpy()\n",
    "        else:\n",
    "            lengths = None\n",
    "        \n",
    "        #pre-process\n",
    "        inputs = self._preprocess_inputs(inputs)\n",
    "        \n",
    "        output, hidden = self._run_rnn(inputs)\n",
    "\n",
    "        if self.attention:\n",
    "            output = self._run_attention(output)\n",
    "        else:\n",
    "            if self.has_batch_dim:\n",
    "                output = self._choose_timestamp(output, idxs=idxs, lengths = lengths)\n",
    "            \n",
    "        output = self._run_regression(output)\n",
    "\n",
    "        y_hat = self._postprocess_outputs(output)\n",
    "\n",
    "        return y_hat\n",
    "    \n",
    "    def _preprocess_inputs(self, inputs):\n",
    "        \"\"\"Apply some function(s) to the input embeddings\n",
    "        This is included to allow for an easy preprocessing hook for\n",
    "        RNNRegression subclasses. For instance, we might want to\n",
    "        apply a tanh to the inputs to make them look more like features\n",
    "        \"\"\"\n",
    "        return inputs\n",
    "    \n",
    "    def _run_rnn(self, inputs):\n",
    "        '''\n",
    "        Run desired RNN\n",
    "        '''\n",
    "        output, hidden = self.rnn(inputs)\n",
    "        output = output.to(self.device) \n",
    "        \n",
    "        return output, hidden\n",
    "    \n",
    "    \n",
    "    def _choose_timestamp(self, output, idxs = None, lengths=None):\n",
    "        # Index extraction for each sequence\n",
    "        if idxs:\n",
    "            curr_idxs = torch.from_numpy(np.array(idxs)).to(self.device)\n",
    "            idx = (curr_idxs).view(-1, 1).expand(output.size(0), output.size(2)).unsqueeze(1).to(self.device)\n",
    "        else:\n",
    "            #Choose last time stamp\n",
    "            curr_idxs = torch.from_numpy(np.array(lengths)).to(self.device)\n",
    "            idx = (curr_idxs - 1).view(-1, 1).expand(output.size(0), output.size(2)).unsqueeze(1).to(self.device)\n",
    "            \n",
    "        return output.gather(1, idx).squeeze()\n",
    "    \n",
    "    def _run_regression(self, h_last):\n",
    "        for i, linear_map in enumerate(self.linear_maps):\n",
    "            if i:\n",
    "                h_last = self._regression_nonlinearity(h_last)\n",
    "            h_last = linear_map(h_last)\n",
    "        return h_last\n",
    "    \n",
    "    def _postprocess_outputs(self, outputs):\n",
    "        \"\"\"Apply some function(s) to the output value(s)\"\"\"\n",
    "        return outputs.squeeze()\n",
    "\n",
    "    def _regression_nonlinearity(self, x):\n",
    "        return F.tanh(x)     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "class EventTypeTrainer(object):\n",
    "    \n",
    "    loss_function_map = {\"linear\": MSELoss,\n",
    "                         \"robust\": L1Loss,\n",
    "                         \"robust_smooth\": SmoothL1Loss,\n",
    "                         \"multinomial\": CrossEntropyLoss}\n",
    "    \n",
    "    def __init__(self, regression_type=\"linear\",\n",
    "                 optimizer_class=torch.optim.Adam,\n",
    "                 device=torch.device(type=\"cpu\"), \n",
    "                 epochs=5,\n",
    "                 rnn_class=LSTM, **kwargs):\n",
    "        \n",
    "        self.epochs = epochs\n",
    "        self.rnn_class = rnn_class\n",
    "        self.device = device\n",
    "    \n",
    "        self._regression_type = regression_type\n",
    "        self._optimizer_class = optimizer_class\n",
    "        self._init_kwargs = kwargs\n",
    "        self._continuous = regression_type != \"multinomial\"\n",
    "        \n",
    "        \n",
    "        \n",
    "    def _initialize_trainer_regression(self):\n",
    "        self._regression = EventTypeRNN(device=self.device,\n",
    "                                             rnn_class=self.rnn_class,\n",
    "                                             **self._init_kwargs)\n",
    "        \n",
    "        self._regression = self._regression.to(self.device)\n",
    "        self.batch_size = self._regression.batch_size\n",
    "       \n",
    "        \n",
    "        self.lf_class = self.__class__.loss_function_map[self._regression_type]\n",
    "\n",
    "        self._loss_function = self.lf_class()\n",
    "        self._loss_function = self._loss_function.to(self.device)\n",
    "        \n",
    "    def fit(self, X, Y, dev, idxs=None, verbosity=1, **kwargs):\n",
    "        \"\"\"Fit the LSTM regression\n",
    "        Parameters\n",
    "        ----------\n",
    "        X : iterable(iterable(object))\n",
    "            a matrix of structures (independent variables) with rows\n",
    "            corresponding to a particular kind of RNN\n",
    "        Y : numpy.array(Number)\n",
    "            a matrix of dependent variables\n",
    "        batch_size : int (default: 100)\n",
    "        verbosity : int (default: 1)\n",
    "            how often to print metrics (never if 0)\n",
    "        \"\"\"\n",
    "\n",
    "        self._X, self._idxs, self._Y = X, idxs, Y\n",
    "        dev_x, dev_idxs, dev_y = dev\n",
    "        \n",
    "        self._initialize_trainer_regression()  \n",
    "        \n",
    "        if not self._continuous:\n",
    "            class_dict = defaultdict(int)\n",
    "            for i in self._Y:\n",
    "                class_dict[i]+=1\n",
    "            class_weights = sorted([(cl,1/num) for cl, num in class_dict.items()], key=lambda x: x[0])\n",
    "            class_weights = [y for x,y in class_weights]\n",
    "            class_weights = torch.FloatTensor(class_weights).to(self.device)\n",
    "            class_weights = class_weights / class_weights.sum(0).expand_as(class_weights)\n",
    "            \n",
    "            self._loss_function = self.lf_class(weight=class_weights)\n",
    "            self._loss_function = self._loss_function.to(self.device)\n",
    "        \n",
    "\n",
    "        print(\"########## .   Model Parameters   ##############\\n\")\n",
    "        for name, param in self._regression.named_parameters():\n",
    "            if param.requires_grad:\n",
    "                print(name, param.shape)\n",
    "        print(\"\\n\")\n",
    "        print(\"##############################################\\n\")\n",
    "        parameters = [p for p in self._regression.parameters() if p.requires_grad]\n",
    "        optimizer = self._optimizer_class(parameters, **kwargs)\n",
    "        \n",
    "        total_obs = len(self._X)\n",
    "        dev_obs = len(dev_x)\n",
    "        \n",
    "        dev_accs = []\n",
    "        train_accs = []\n",
    "        best_val_acc = -float('inf')\n",
    "        \n",
    "        for epoch in range(self.epochs):\n",
    "            # Turn on training mode which enables dropout.\n",
    "            self._regression.train()\n",
    "            \n",
    "            bidx_i = 0\n",
    "            bidx_j =self.batch_size\n",
    "            \n",
    "            tqdm.write(\"Running Epoch: {}\".format(epoch+1))\n",
    "            \n",
    "            #time print\n",
    "            pbar = tqdm_n(total = total_obs//self.batch_size)\n",
    "            \n",
    "            while bidx_j < total_obs:\n",
    "                words = self._X[bidx_i:bidx_j]\n",
    "                \n",
    "                indexes = self._idxs[bidx_i:bidx_j]\n",
    "                targets = self._Y[bidx_i:bidx_j]\n",
    "            \n",
    "                #Zero grad\n",
    "                optimizer.zero_grad()\n",
    "\n",
    "                #Calculate Loss\n",
    "                predicts = self._regression(words, idxs=indexes)          \n",
    "                actuals = torch.from_numpy(np.array(targets)).to(self.device)\n",
    "                \n",
    "                curr_loss = self._loss_function(predicts, actuals)\n",
    "                \n",
    "                #Backpropagate\n",
    "                curr_loss.backward()\n",
    "                optimizer.step()\n",
    "                bidx_i = bidx_j\n",
    "                bidx_j = bidx_i + self.batch_size\n",
    "                \n",
    "                if bidx_j >= total_obs:\n",
    "                    words = self._X[bidx_i:bidx_j]\n",
    "                    indexes = self._idxs[bidx_i:bidx_j]\n",
    "                    targets = self._Y[bidx_i:bidx_j]\n",
    "\n",
    "                    #Zero grad\n",
    "                    optimizer.zero_grad()\n",
    "                    \n",
    "                    #Calculate Loss\n",
    "                    predicts = self._regression(words, idxs=indexes)          \n",
    "                    actuals = torch.from_numpy(np.array(targets)).to(self.device)\n",
    "                    curr_loss = self._loss_function(predicts, actuals)\n",
    "                    \n",
    "                    #Backpropagate\n",
    "                    curr_loss.backward()\n",
    "                    optimizer.step()\n",
    "                    \n",
    "                pbar.update(1)\n",
    "                    \n",
    "            pbar.close()\n",
    "            \n",
    "            #train_predicts = self.predict(self._X, idxs=self._idxs) \n",
    "            dev_predicts = self.predict(dev_x, idxs=dev_idxs)\n",
    "            \n",
    "            #train_acc = spearmanr(train_predicts, Y)\n",
    "            dev_acc = spearmanr(dev_predicts, dev_y)\n",
    "            \n",
    "            del dev_predicts\n",
    "            \n",
    "            # Save the model if the validation loss is the best we've seen so far.\n",
    "            if dev_acc[0] > best_val_acc:\n",
    "                with open(best_model_file, 'wb') as f:\n",
    "                    torch.save(self._regression.state_dict(), f)\n",
    "                best_val_acc = dev_acc[0]\n",
    "    \n",
    "            tqdm.write(\"Epoch: {} Loss: {}\".format(epoch+1, curr_loss))\n",
    "            #tqdm.write(\"Train spearman correlation: {0:.5f} P-value: {1:.5f}\".format(train_acc[0], train_acc[1]))\n",
    "            tqdm.write(\"Dev spearman correlation: {0:.5f} P-value: {1:.5f}\".format(dev_acc[0], dev_acc[1]))\n",
    "            tqdm.write(\"\\n\")\n",
    "            dev_accs.append(dev_acc[0])\n",
    "            #train_accs.append(train_acc[0])\n",
    "            \n",
    "        return dev_accs\n",
    "            \n",
    "        \n",
    "    def predict(self, X, idxs=None, batch=1024):\n",
    "        \"\"\"Predict using the LSTM regression\n",
    "        Parameters\n",
    "        ----------\n",
    "        X : iterable(iterable(object))\n",
    "            a matrix of structures (independent variables) with rows\n",
    "            corresponding to a particular kind of RNN\n",
    "        \"\"\"\n",
    "        # Turn on evaluation mode which disables dropout.\n",
    "        self._regression.eval()\n",
    "        \n",
    "        with torch.no_grad():  \n",
    "            bidx_i = 0\n",
    "            bidx_j = batch\n",
    "            total_obs = len(X)\n",
    "            predictions = torch.zeros(total_obs, self._init_kwargs['output_size']).to(self.device)\n",
    "            \n",
    "            while bidx_j < total_obs:\n",
    "                words = X[bidx_i:bidx_j]\n",
    "                indexes = idxs[bidx_i:bidx_j]\n",
    "                predicts = self._regression(words, idxs=indexes) \n",
    "                predictions[bidx_i:bidx_j] = predicts\n",
    "\n",
    "                bidx_i = bidx_j\n",
    "                bidx_j = bidx_i + batch\n",
    "\n",
    "                if bidx_j >= total_obs:\n",
    "                    words = X[bidx_i:bidx_j]\n",
    "                    indexes = idxs[bidx_i:bidx_j]\n",
    "                    predicts = self._regression(words, idxs=indexes) \n",
    "                    predictions[bidx_i:bidx_j] = predicts\n",
    "\n",
    "            predictions = F.softmax(predictions, dim=1)\n",
    "\n",
    "            _ , predictions =  predictions.max(1)\n",
    "        \n",
    "        return predictions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data as per model format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "t_obs = len(X_train)\n",
    "#t_obs = 600\n",
    "X = [i for i, j in X_train[:t_obs].values]\n",
    "indexes = [j for i, j in X_train[:t_obs].values]\n",
    "targets = Y_train[:t_obs].values\n",
    "\n",
    "d_obs = len(X_dev)\n",
    "#d_obs = 1080\n",
    "dev_X = [i for i, j in X_dev[:d_obs].values]\n",
    "dev_indexes = [j for i, j in X_dev[:d_obs].values]\n",
    "dev_targets = Y_dev[:d_obs].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "dev = (dev_X, dev_indexes, dev_targets)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Initialize the model and Fit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = EventTypeTrainer(rnn_class = LSTM, embedding_size = 1024,\n",
    "                          rnn_hidden_size = 300, num_rnn_layers=2, device=torch.device('cuda')  ,\n",
    "                         bidirectional=True, epochs=5, attention=False,rnn_dropout=0.5,\n",
    "                          regression_hidden_sizes = [24], output_size = 11, \n",
    "                            batch_size=128, regression_type=\"multinomial\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "########## .   Model Parameters   ##############\n",
      "\n",
      "rnn.weight_ih_l0 torch.Size([1200, 1024])\n",
      "rnn.weight_hh_l0 torch.Size([1200, 300])\n",
      "rnn.bias_ih_l0 torch.Size([1200])\n",
      "rnn.bias_hh_l0 torch.Size([1200])\n",
      "rnn.weight_ih_l0_reverse torch.Size([1200, 1024])\n",
      "rnn.weight_hh_l0_reverse torch.Size([1200, 300])\n",
      "rnn.bias_ih_l0_reverse torch.Size([1200])\n",
      "rnn.bias_hh_l0_reverse torch.Size([1200])\n",
      "rnn.weight_ih_l1 torch.Size([1200, 600])\n",
      "rnn.weight_hh_l1 torch.Size([1200, 300])\n",
      "rnn.bias_ih_l1 torch.Size([1200])\n",
      "rnn.bias_hh_l1 torch.Size([1200])\n",
      "rnn.weight_ih_l1_reverse torch.Size([1200, 600])\n",
      "rnn.weight_hh_l1_reverse torch.Size([1200, 300])\n",
      "rnn.bias_ih_l1_reverse torch.Size([1200])\n",
      "rnn.bias_hh_l1_reverse torch.Size([1200])\n",
      "linear_maps.0.weight torch.Size([24, 600])\n",
      "linear_maps.0.bias torch.Size([24])\n",
      "linear_maps.1.weight torch.Size([11, 24])\n",
      "linear_maps.1.bias torch.Size([11])\n",
      "\n",
      "\n",
      "##############################################\n",
      "\n",
      "Running Epoch: 1\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "421c084d21e84aab9291386dc94a50b3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=183), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch: 1 Loss: 1.8767635822296143\n",
      "Dev spearman correlation: 0.08799 P-value: 0.00000\n",
      "\n",
      "\n",
      "Running Epoch: 2\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1c4a5753f35a4662b2ca09adfb785ad2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=183), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch: 2 Loss: 1.7728654146194458\n",
      "Dev spearman correlation: 0.08666 P-value: 0.00000\n",
      "\n",
      "\n",
      "Running Epoch: 3\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fb3b6aa07a3c48fdae299ada2c5ebe99",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=183), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch: 3 Loss: 1.655367374420166\n",
      "Dev spearman correlation: 0.08562 P-value: 0.00000\n",
      "\n",
      "\n",
      "Running Epoch: 4\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4a7382ff6ddb4e3bb6bfb25e79eb1bbf",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=183), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch: 4 Loss: 1.565590262413025\n",
      "Dev spearman correlation: 0.06606 P-value: 0.00039\n",
      "\n",
      "\n",
      "Running Epoch: 5\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2998e485e64644089f1d2de4bf97113f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=183), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch: 5 Loss: 1.454863429069519\n",
      "Dev spearman correlation: 0.07820 P-value: 0.00003\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "dev_accs = model.fit(X, targets, dev, idxs = indexes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plot Performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plt.plot(train_accs, 'b-', label=\"train\")\n",
    "# plt.plot(dev_accs, 'r-', label=\"dev\")\n",
    "# plt.xlabel(\"Epochs\")\n",
    "# plt.ylabel(\"Spearman Correlation\")\n",
    "# plt.title(\"Performance on Event Durations\")\n",
    "# plt.legend()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
